#!/bin/bash

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  Dig|lit Ultimate Setup - Six Sigma Edition                     â•‘
# â•‘  99.99966% Defect-Free Analysis, Fix & Progress Tracking        â•‘
# â•‘  Enhanced with AI Analysis, Self-Healing & Predictive Logic     â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ythoâ•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -euo pipefail  # Strict error handling
IFS=$'\n\t'        # Safe field separator

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONSTANTS & CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

readonly SCRIPT_VERSION="2.0.0-SixSigma"
readonly SCRIPT_NAME="$(basename "$0")"
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="${SCRIPT_DIR}"

# Color codes (readonly for immutability)
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly PURPLE='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly BOLD='\033[1m'
readonly NC='\033[0m'

# Directory structure
readonly FRONTEND_DIR="${PROJECT_ROOT}/FRONTEND"
readonly Z_DIR="${PROJECT_ROOT}/Z"
readonly REPORT_DIR="${Z_DIR}/REPORTS"
readonly BACKUP_DIR="${Z_DIR}/BACKUPS"
readonly LOG_DIR="${Z_DIR}/LOGS"

# File paths
readonly TIMESTAMP="$(date +%Y%m%d_%H%M%S)"
readonly REPORT_FILE="${REPORT_DIR}/report_${TIMESTAMP}.md"
readonly LOG_FILE="${LOG_DIR}/execution_${TIMESTAMP}.log"
readonly ERROR_LOG="${LOG_DIR}/errors_${TIMESTAMP}.log"
readonly AI_COMMANDER_FILE="ai_commander_core.py"

# Six Sigma tracking
declare -i TOTAL_CHECKS=0
declare -i CHECKS_PASSED=0
declare -i CHECKS_FAILED=0
declare -i WARNINGS=0
declare -i CRITICAL_ISSUES=0
declare -i ISSUES_FIXED=0
declare -i AUTO_HEALS=0

# Performance tracking
readonly START_TIME=$(date +%s)
declare -A EXECUTION_TIMES

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGGING & OUTPUT SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Initialize logging system
init_logging() {
    mkdir -p "${REPORT_DIR}" "${BACKUP_DIR}" "${LOG_DIR}"
    exec 1> >(tee -a "${LOG_FILE}")
    exec 2> >(tee -a "${ERROR_LOG}" >&2)
    log_info "Logging initialized: ${LOG_FILE}"
}

# Structured logging with timestamps and levels
log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[${timestamp}] [${level}] ${message}" | tee -a "${LOG_FILE}"
}

log_info() { log "INFO" "$@"; }
log_warn() { log "WARN" "$@"; ((WARNINGS++)); }
log_error() { log "ERROR" "$@"; ((CHECKS_FAILED++)); }
log_critical() { log "CRITICAL" "$@"; ((CRITICAL_ISSUES++)); }
log_success() { log "SUCCESS" "$@"; ((CHECKS_PASSED++)); }

# Visual output functions with validation
print_header() {
    local msg="$1"
    echo -e "\n${BOLD}${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${BOLD}${CYAN}â•‘  ${msg}${NC}"
    echo -e "${BOLD}${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"
    log_info "Section: ${msg}"
}

print_section() {
    echo -e "\n${BOLD}${BLUE}â–¶ $1${NC}"
    log_info "Subsection: $1"
}

check() {
    ((TOTAL_CHECKS++))
    echo -e "${YELLOW}âš™${NC} $1..."
    log_info "Check: $1"
}

success() {
    echo -e "${GREEN}âœ“${NC} $1"
    log_success "$1"
}

warning() {
    echo -e "${YELLOW}âš ${NC} $1"
    log_warn "$1"
}

error() {
    echo -e "${RED}âœ—${NC} $1"
    log_error "$1"
}

critical() {
    echo -e "${RED}${BOLD}âš  CRITICAL:${NC} $1"
    log_critical "$1"
}

fixed() {
    ((ISSUES_FIXED++))
    echo -e "${GREEN}ğŸ”§${NC} $1"
    log_success "Fixed: $1"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MATH HELPER FUNCTIONS (bc fallback)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

safe_divide() {
    local numerator=$1
    local denominator=$2
    local scale=${3:-2}

    if [[ $denominator -eq 0 ]]; then
        echo "0"
        return
    fi

    if command -v bc &> /dev/null; then
        echo "scale=${scale}; ${numerator} / ${denominator}" | bc
    else
        awk "BEGIN {printf \"%.${scale}f\", ${numerator} / ${denominator}}"
    fi
}

safe_multiply() {
    local num1=$1
    local num2=$2
    local scale=${3:-2}

    if command -v bc &> /dev/null; then
        echo "scale=${scale}; ${num1} * ${num2}" | bc
    else
        awk "BEGIN {printf \"%.${scale}f\", ${num1} * ${num2}}"
    fi
}

safe_compare() {
    local num1=$1
    local operator=$2
    local num2=$3

    if command -v bc &> /dev/null; then
        result=$(echo "${num1} ${operator} ${num2}" | bc)
        [[ $result -eq 1 ]]
    else
        awk "BEGIN {exit !(${num1} ${operator} ${num2})}"
    fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDATION & PRECONDITION CHECKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

validate_environment() {
    print_section "Environment Validation"

    local validation_failed=0

    # Check required commands with auto-install capability
    local required_commands=("grep" "sed" "find" "sort" "uniq" "sha256sum" "python3" "git")
    local optional_commands=("bc")

    for cmd in "${required_commands[@]}"; do
        if command -v "$cmd" &> /dev/null; then
            success "Command available: $cmd"
        else
            error "Required command not found: $cmd"
            validation_failed=1
        fi
    done

    for cmd in "${optional_commands[@]}"; do
        if command -v "$cmd" &> /dev/null; then
            success "Command available: $cmd"
        else
            warning "Optional command not found: $cmd"
            echo -e "${YELLOW}  To install: sudo apt-get install -y $cmd${NC}"
            echo -e "${YELLOW}  Fallback calculations will be used${NC}"
        fi
    done

    if [[ -w "${PROJECT_ROOT}" ]]; then
        success "Project root is writable"
    else
        critical "Project root is not writable: ${PROJECT_ROOT}"
        validation_failed=1
    fi

    local available_space
    available_space=$(df -BM "${PROJECT_ROOT}" | awk 'NR==2 {print $4}' | sed 's/M//')
    if [[ ${available_space} -gt 100 ]]; then
        success "Sufficient disk space: ${available_space}MB available"
    else
        warning "Low disk space: ${available_space}MB available"
    fi

    if [[ ! -d "${Z_DIR}" ]]; then
        warning "Z directory missing, creating..."
        mkdir -p "${Z_DIR}" && fixed "Z directory created"
    fi

    return ${validation_failed}
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKUP & ROLLBACK SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

create_backup() {
    local file="$1"
    local backup_name="${BACKUP_DIR}/$(basename "${file}").${TIMESTAMP}.backup"

    if [[ -f "${file}" ]]; then
        cp -p "${file}" "${backup_name}" && \
            success "Backup created: ${backup_name}" || \
            error "Failed to create backup for ${file}"
        echo "${backup_name}"
    else
        warning "File not found for backup: ${file}"
        return 1
    fi
}

restore_backup() {
    local backup_file="$1"
    local original_file="$2"

    if [[ -f "${backup_file}" ]]; then
        cp -p "${backup_file}" "${original_file}" && \
            success "Restored from backup: ${original_file}" || \
            error "Failed to restore backup"
    else
        error "Backup file not found: ${backup_file}"
        return 1
    fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SURGICAL AI COMMANDER ANALYSIS WITH SELF-HEALING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

analyze_ai_commander() {
    print_section "Surgical AI Commander Analysis"

    local ai_file="${PROJECT_ROOT}/${AI_COMMANDER_FILE}"
    local bugs_found=0
    local fixes_applied=0
    local backup_created=""

    if [[ ! -f "${ai_file}" ]]; then
        error "AI Commander file not found: ${ai_file}"

        check "Searching for AI Commander in alternate locations"
        local found_file
        found_file=$(find "${PROJECT_ROOT}" -name "${AI_COMMANDER_FILE}" -type f 2>/dev/null | head -1)

        if [[ -n "${found_file}" ]]; then
            warning "Found AI Commander at: ${found_file}"
            ai_file="${found_file}"
            ((AUTO_HEALS++))
        else
            critical "Cannot locate AI Commander file anywhere"
            return 1
        fi
    fi

    success "AI Commander located: ${ai_file}"

    check "Creating safety backup"
    backup_created=$(create_backup "${ai_file}" || echo "")

    check "Scanning for boolean call syntax errors"

    if grep -nE 'any\([^)]+\)\(\)' "${ai_file}" > /dev/null 2>&1; then
        error "Critical bug: Boolean generator expression called as function"
        ((bugs_found++))

        check "Applying surgical fix for boolean call"
        sed -i.tmp 's/any(\([^)]*\))()/any(\1)/g' "${ai_file}"

        if [[ $? -eq 0 ]]; then
            if python3 -m py_compile "${ai_file}" 2>/dev/null; then
                fixed "Boolean call syntax corrected and validated"
                ((fixes_applied++))
                rm -f "${ai_file}.tmp"
            else
                error "Fix introduced syntax errors, rolling back"
                [[ -n "${backup_created}" ]] && restore_backup "${backup_created}" "${ai_file}"
                rm -f "${ai_file}.tmp"
            fi
        fi
    else
        success "No boolean call syntax errors detected"
    fi

    check "Checking print statement compatibility"
    if grep -nE 'print\s+[^(]' "${ai_file}" | grep -v '^[[:space:]]*#' > /dev/null 2>&1; then
        warning "Potential Python 2/3 print compatibility issues detected"
        ((bugs_found++))
        echo "  Consider converting to Python 3 print() functions"
    else
        success "Print statements are Python 3 compatible"
    fi

    check "Validating import statements"
    if grep -q 'import sys' "${ai_file}"; then
        success "Standard library imports present"
    else
        warning "No sys import detected (may be intentional)"
    fi

    check "Validating complete Python syntax"
    local syntax_check_output
    syntax_check_output=$(python3 -m py_compile "${ai_file}" 2>&1) || true

    if [[ $? -eq 0 ]]; then
        success "Python syntax validation passed"
    else
        error "Python syntax errors found:"
        echo "${syntax_check_output}" | head -5
        ((bugs_found++))
    fi

    check "Analyzing code structure"
    local function_count class_count line_count comment_count
    function_count=$(grep -cE '^[[:space:]]*def ' "${ai_file}" || echo 0)
    class_count=$(grep -cE '^[[:space:]]*class ' "${ai_file}" || echo 0)
    line_count=$(wc -l < "${ai_file}")
    comment_count=$(grep -cE '^[[:space:]]*#' "${ai_file}" || echo 0)

    echo -e "${CYAN}Code Metrics:${NC}"
    echo -e "  Functions:     ${function_count}"
    echo -e "  Classes:       ${class_count}"
    echo -e "  Total Lines:   ${line_count}"
    echo -e "  Comments:      ${comment_count}"
    echo -e "  Bugs Found:    ${bugs_found}"
    echo -e "  Fixes Applied: ${fixes_applied}"

    local quality_score=100
    ((quality_score -= bugs_found * 10))
    ((quality_score += fixes_applied * 5))

    if [[ ${quality_score} -ge 90 ]]; then
        success "Code quality score: ${quality_score}/100 (Excellent)"
    elif [[ ${quality_score} -ge 70 ]]; then
        warning "Code quality score: ${quality_score}/100 (Good)"
    else
        error "Code quality score: ${quality_score}/100 (Needs improvement)"
    fi

    export AI_BUGS_FOUND=${bugs_found}
    export AI_FIXES_APPLIED=${fixes_applied}
    export AI_QUALITY_SCORE=${quality_score}

    return 0
}
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADVANCED DUPLICATE DETECTION WITH SIMILARITY ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

detect_duplicates() {
    print_section "Advanced Duplicate Detection"

    local checksum_file="${REPORT_DIR}/checksums_${TIMESTAMP}.txt"
    local duplicates_file="${REPORT_DIR}/duplicates_${TIMESTAMP}.txt"
    local similar_file="${REPORT_DIR}/similar_${TIMESTAMP}.txt"

    check "Computing file checksums (excluding build artifacts)"

    local exclude_pattern='-path "*/node_modules/*" -o -path "*/.git/*" -o -path "*/__pycache__/*" -o -path "*/dist/*" -o -path "*/build/*"'

    find "${PROJECT_ROOT}" -type f \( ${exclude_pattern} \) -prune -o -type f -print0 2>/dev/null | \
        xargs -0 sha256sum 2>/dev/null | \
        grep -v 'node_modules\|\.git\|__pycache__' > "${checksum_file}" || true

    local total_files
    total_files=$(wc -l < "${checksum_file}")
    success "Analyzed ${total_files} files"

    check "Identifying exact duplicates"
    awk '{print $1}' "${checksum_file}" | sort | uniq -d > "${duplicates_file}.hashes"

    : > "${duplicates_file}"
    while IFS= read -r hash; do
        grep "^${hash}" "${checksum_file}" >> "${duplicates_file}"
    done < "${duplicates_file}.hashes"

    local dup_count
    dup_count=$(wc -l < "${duplicates_file}")

    if [[ ${dup_count} -gt 0 ]]; then
        warning "Found ${dup_count} duplicate file entries"

        echo -e "\n${CYAN}Duplicate Groups:${NC}"
        local group_num=1
        while IFS= read -r hash; do
            echo -e "${YELLOW}Group ${group_num}:${NC}"
            grep "^${hash}" "${checksum_file}" | awk '{print "  " $2}'
            ((group_num++))
        done < "${duplicates_file}.hashes" | head -20
    else
        success "No exact duplicates found"
    fi

    check "Detecting similar filenames"
    find "${PROJECT_ROOT}" -type f \( ${exclude_pattern} \) -prune -o -type f -printf "%f\n" 2>/dev/null | \
        sort | uniq -d > "${similar_file}"

    local similar_count
    similar_count=$(wc -l < "${similar_file}")

    if [[ ${similar_count} -gt 0 ]]; then
        warning "Found ${similar_count} files with identical names in different locations"
    else
        success "No filename collisions detected"
    fi

    rm -f "${duplicates_file}.hashes"

    export DUP_COUNT=${dup_count}
    export SIMILAR_COUNT=${similar_count}
    export DUPLICATES_FILE="${duplicates_file}"
    export SIMILAR_FILE="${similar_file}"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTELLIGENT PROJECT STRUCTURE ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

analyze_project_structure() {
    print_section "Intelligent Project Structure Analysis"

    local tree_file="${REPORT_DIR}/project_tree_${TIMESTAMP}.txt"

    check "Generating complete project tree"
    find "${PROJECT_ROOT}" -type f \
        -not -path "*/node_modules/*" \
        -not -path "*/.git/*" \
        -not -path "*/__pycache__/*" \
        -not -path "*/dist/*" \
        -not -path "*/build/*" \
        2>/dev/null | sort > "${tree_file}"

    local total_files
    total_files=$(wc -l < "${tree_file}")
    success "Project tree generated: ${total_files} files indexed"

    check "Analyzing file type distribution"
    echo -e "\n${CYAN}File Type Distribution:${NC}"

    declare -A file_types=()
    while IFS= read -r file; do
        if [[ "$file" == *.* ]]; then
            ext="${file##*.}"
            ((file_types["${ext}"]++))
        else
            ((file_types["no-extension"]++))
        fi
    done < "${tree_file}"

    for ext in "${!file_types[@]}"; do
        echo "${file_types[$ext]} ${ext}"
    done | sort -rn | head -10 | while read -r count ext; do
        echo -e "  ${BLUE}${count}${NC} .${ext} files"
    done

    check "Analyzing directory structure depth"
    local max_depth
    max_depth=$(find "${PROJECT_ROOT}" -type d \
        -not -path "*/node_modules/*" \
        -not -path "*/.git/*" 2>/dev/null | \
        awk -F'/' '{print NF}' | sort -n | tail -1)

    echo -e "${CYAN}Structure Depth:${NC} ${max_depth} levels"

    check "Detecting large files (>1MB)"
    local large_files
    large_files=$(find "${PROJECT_ROOT}" -type f -size +1M \
        -not -path "*/node_modules/*" \
        -not -path "*/.git/*" 2>/dev/null | wc -l)

    if [[ ${large_files} -gt 0 ]]; then
        warning "Found ${large_files} files larger than 1MB"
    else
        success "No unusually large files detected"
    fi

    export PROJECT_TREE_FILE="${tree_file}"
    export TOTAL_FILES=${total_files}
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPREHENSIVE CONTENT GAP ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

analyze_content_gaps() {
    print_section "Content Gap & Quality Analysis"

    local code_files
    code_files=$(find "${PROJECT_ROOT}" \( -name "*.py" -o -name "*.js" -o -name "*.ts" -o -name "*.jsx" -o -name "*.tsx" \) \
        -not -path "*/node_modules/*" 2>/dev/null | wc -l)

    local doc_files
    doc_files=$(find "${PROJECT_ROOT}" \( -name "*.md" -o -name "*.txt" -o -name "*.rst" \) \
        -not -path "*/node_modules/*" 2>/dev/null | wc -l)

    local test_files
    test_files=$(find "${PROJECT_ROOT}" \( -name "*test*.py" -o -name "*test*.js" -o -name "*.spec.*" \) \
        -not -path "*/node_modules/*" 2>/dev/null | wc -l)

    echo -e "${CYAN}Content Distribution:${NC}"
    echo -e "  Code Files:    ${code_files}"
    echo -e "  Documentation: ${doc_files}"
    echo -e "  Test Files:    ${test_files}"

    local doc_ratio="N/A"
    if [[ ${code_files} -gt 0 ]]; then
        doc_ratio=$(safe_divide ${doc_files} ${code_files} 3)
    fi

    local test_ratio="N/A"
    if [[ ${code_files} -gt 0 ]]; then
        test_ratio=$(safe_divide ${test_files} ${code_files} 3)
    fi

    echo -e "  Doc/Code Ratio:  ${doc_ratio}"
    echo -e "  Test/Code Ratio: ${test_ratio}"

    if [[ "${doc_ratio}" != "N/A" ]]; then
        local doc_ratio_int
        doc_ratio_int=$(awk "BEGIN {printf \"%.0f\", ${doc_ratio} * 100}")
        if [[ ${doc_ratio_int} -ge 50 ]]; then
            success "Documentation coverage is excellent"
        elif [[ ${doc_ratio_int} -ge 20 ]]; then
            warning "Documentation coverage is adequate but could be improved"
        else
            error "Documentation coverage is insufficient"
        fi
    fi

    check "Validating critical project files"
    local critical_files=("package.json" "README.md" "requirements.txt" ".gitignore" "LICENSE")
    local missing_critical=0

    echo -e "\n${CYAN}Critical Files Check:${NC}"
    for file in "${critical_files[@]}"; do
        if find "${PROJECT_ROOT}" -maxdepth 2 -name "${file}" -type f 2>/dev/null | grep -q .; then
            echo -e "  ${GREEN}âœ“${NC} ${file}"
        else
            echo -e "  ${RED}âœ—${NC} ${file}"
            ((missing_critical++))
        fi
    done

    if [[ ${missing_critical} -eq 0 ]]; then
        success "All critical files present"
    else
        warning "Missing ${missing_critical} critical files"
    fi

    export CODE_FILES=${code_files}
    export DOC_FILES=${doc_files}
    export TEST_FILES=${test_files}
    export DOC_RATIO="${doc_ratio}"
    export TEST_RATIO="${test_ratio}"
    export MISSING_CRITICAL=${missing_critical}
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIX SIGMA QUALITY METRICS CALCULATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

calculate_six_sigma_metrics() {
    print_section "Six Sigma Quality Metrics"

    local defect_rate=0
    if [[ ${TOTAL_CHECKS} -gt 0 ]]; then
        defect_rate=$(safe_multiply "$(safe_divide $((CHECKS_FAILED + CRITICAL_ISSUES)) ${TOTAL_CHECKS} 6)" 100 2)
    fi

    local pass_rate=0
    if [[ ${TOTAL_CHECKS} -gt 0 ]]; then
        pass_rate=$(safe_multiply "$(safe_divide ${CHECKS_PASSED} ${TOTAL_CHECKS} 4)" 100 2)
    fi

    local sigma_level="N/A"
    local dpmo=0

    if [[ ${TOTAL_CHECKS} -gt 0 ]]; then
        dpmo=$(awk "BEGIN {printf \"%.0f\", (${CHECKS_FAILED} + ${CRITICAL_ISSUES}) * 1000000 / ${TOTAL_CHECKS}}")

        if [[ ${dpmo} -le 3 ]]; then
            sigma_level="6Ïƒ (World Class)"
        elif [[ ${dpmo} -le 233 ]]; then
            sigma_level="5Ïƒ (Excellent)"
        elif [[ ${dpmo} -le 6210 ]]; then
            sigma_level="4Ïƒ (Good)"
        elif [[ ${dpmo} -le 66807 ]]; then
            sigma_level="3Ïƒ (Average)"
        else
            sigma_level="<3Ïƒ (Poor)"
        fi
    fi

    echo -e "${CYAN}Quality Metrics:${NC}"
    echo -e "  Total Checks:      ${TOTAL_CHECKS}"
    echo -e "  Passed:            ${CHECKS_PASSED}"
    echo -e "  Failed:            ${CHECKS_FAILED}"
    echo -e "  Critical Issues:   ${CRITICAL_ISSUES}"
    echo -e "  Warnings:          ${WARNINGS}"
    echo -e "  Auto-Heals:        ${AUTO_HEALS}"
    echo -e "  Pass Rate:         ${pass_rate}%"
    echo -e "  Defect Rate:       ${defect_rate}%"
    echo -e "  DPMO:              ${dpmo}"
    echo -e "  Sigma Level:       ${sigma_level}"

    if [[ ${dpmo} -le 3 ]]; then
        success "Project quality meets Six Sigma standards!"
    elif [[ ${dpmo} -le 233 ]]; then
        success "Project quality is excellent (Five Sigma)"
    elif [[ ${dpmo} -le 6210 ]]; then
        warning "Project quality is good but has room for improvement"
    else
        error "Project quality needs significant improvement"
    fi

    export SIGMA_LEVEL="${sigma_level}"
    export DPMO=${dpmo}
    export PASS_RATE="${pass_rate}"
    export DEFECT_RATE="${defect_rate}"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENHANCED REPORT GENERATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

generate_enhanced_report() {
    print_section "Generating Six Sigma Analysis Report"

    local end_time
    end_time=$(date +%s)
    local execution_time=$((end_time - START_TIME))

    local node_version npm_version python_version
    node_version=$(node --version 2>/dev/null || echo "N/A")
    npm_version=$(npm --version 2>/dev/null || echo "N/A")
    python_version=$(python3 --version 2>/dev/null || echo "N/A")

    local git_branch="N/A"
    local git_commit="N/A"
    local git_status="N/A"

    if [[ -d "${PROJECT_ROOT}/.git" ]]; then
        git_branch=$(git branch --show-current 2>/dev/null || echo "N/A")
        git_commit=$(git rev-parse --short HEAD 2>/dev/null || echo "N/A")
        git_status=$(git status --porcelain 2>/dev/null | wc -l)
    fi

    # Use eval to expand variables inside heredoc
    cat > "${REPORT_FILE}" << REPORT_EOF
# Dig|lit Six Sigma Analysis Report

**Generated:** $(date '+%Y-%m-%d %H:%M:%S')  
**Script Version:** ${SCRIPT_VERSION}  
**Execution Time:** ${execution_time} seconds

---

## Executive Summary

### Six Sigma Quality Metrics
- **Sigma Level:** ${SIGMA_LEVEL}
- **DPMO:** ${DPMO} defects per million opportunities
- **Pass Rate:** ${PASS_RATE}%
- **Defect Rate:** ${DEFECT_RATE}%

### Overall Status
- **Total Checks:** ${TOTAL_CHECKS}
- **Passed:** ${CHECKS_PASSED} âœ…
- **Failed:** ${CHECKS_FAILED} âŒ
- **Warnings:** ${WARNINGS} âš ï¸
- **Critical Issues:** ${CRITICAL_ISSUES} ğŸš¨
- **Issues Fixed:** ${ISSUES_FIXED} ğŸ”§
- **Auto-Heals:** ${AUTO_HEALS} ğŸ¥

---

## Project Information

### Git Repository
- **Branch:** ${git_branch}
- **Commit:** ${git_commit}
- **Uncommitted Changes:** ${git_status}

### Environment
- **Node.js:** ${node_version}
- **npm:** ${npm_version}
- **Python:** ${python_version}

---

## AI Commander Analysis

### Status
- **File:** ${AI_COMMANDER_FILE}
- **Location:** $([ -f "${PROJECT_ROOT}/${AI_COMMANDER_FILE}" ] && echo "Found" || echo "Not Found")
- **Bugs Detected:** ${AI_BUGS_FOUND:-0}
- **Fixes Applied:** ${AI_FIXES_APPLIED:-0}
- **Quality Score:** ${AI_QUALITY_SCORE:-N/A}/100

### Issues Detected
$(if [[ ${AI_BUGS_FOUND:-0} -gt 0 ]]; then
    echo "- Boolean call syntax errors"
    echo "- See detailed logs in ${LOG_FILE}"
else
    echo "- No issues detected âœ…"
fi)

---

## Project Structure Analysis

### File Statistics
- **Total Files:** ${TOTAL_FILES:-0}
- **Code Files:** ${CODE_FILES:-0}
- **Documentation:** ${DOC_FILES:-0}
- **Test Files:** ${TEST_FILES:-0}

### Quality Ratios
- **Documentation/Code:** ${DOC_RATIO:-N/A}
- **Test/Code:** ${TEST_RATIO:-N/A}
- **Missing Critical Files:** ${MISSING_CRITICAL:-0}

### Duplicate Analysis
- **Exact Duplicates:** ${DUP_COUNT:-0}
- **Similar Filenames:** ${SIMILAR_COUNT:-0}

---

## Critical Issues & Recommendations

### High Priority
$(if [[ ${CRITICAL_ISSUES} -gt 0 ]]; then
    echo "âš ï¸ **${CRITICAL_ISSUES} critical issues** require immediate attention"
    echo "- Review error log: ${ERROR_LOG}"
else
    echo "âœ… No critical issues detected"
fi)

$(if [[ ${AI_BUGS_FOUND:-0} -gt 0 ]]; then
    echo "âš ï¸ **AI Commander has bugs** - ${AI_FIXES_APPLIED:-0} fixes applied"
    echo "- Test AI Commander thoroughly before deployment"
else
    echo "âœ… AI Commander passed all checks"
fi)

### Medium Priority
$(if [[ ${DUP_COUNT:-0} -gt 0 ]]; then
    echo "âš ï¸ **${DUP_COUNT} duplicate files** detected"
    echo "- Review: ${DUPLICATES_FILE}"
    echo "- Consider deduplication to save space"
else
    echo "âœ… No duplicate files found"
fi)

$(if [[ ${MISSING_CRITICAL:-0} -gt 0 ]]; then
    echo "âš ï¸ **${MISSING_CRITICAL} critical files** missing"
    echo "- Add missing project configuration files"
else
    echo "âœ… All critical project files present"
fi)

### Recommendations
1. **Code Quality**
   - Current Sigma Level: ${SIGMA_LEVEL}
   - Target: Maintain or improve to 6Ïƒ

2. **Documentation**
   - Current Ratio: ${DOC_RATIO:-N/A}
   - Recommended: >0.5 (one doc per two code files)

3. **Testing**
   - Current Ratio: ${TEST_RATIO:-N/A}
   - Recommended: >0.8 (80% test coverage)

4. **Maintenance**
   - Review and remove duplicate files
   - Update outdated dependencies
   - Improve error handling in critical paths

---

## Generated Artifacts

### Reports & Logs
- **Main Report:** ${REPORT_FILE}
- **Execution Log:** ${LOG_FILE}
- **Error Log:** ${ERROR_LOG}
- **Project Tree:** ${PROJECT_TREE_FILE:-N/A}

### Analysis Files
- **Duplicates:** ${DUPLICATES_FILE:-N/A}
- **Similar Files:** ${SIMILAR_FILE:-N/A}

### Backups
- Location: ${BACKUP_DIR}
- Auto-created before any modifications

---

## Quick Action Commands

### Start Development
\`\`\`bash
cd ${FRONTEND_DIR} && npm run dev
\`\`\`

### Review Issues
\`\`\`bash
# View duplicates
cat ${DUPLICATES_FILE:-/dev/null}

# View error log
cat ${ERROR_LOG}

# View project structure
cat ${PROJECT_TREE_FILE:-/dev/null}
\`\`\`

### Fix Issues
\`\`\`bash
# Run targeted fix
${SCRIPT_NAME} fix-ai

# Full analysis
${SCRIPT_NAME} analyze

# Check duplicates only
${SCRIPT_NAME} duplicates
\`\`\`

### Test AI Commander
\`\`\`bash
cd Z/DigIlit-Envisioned && python3 ${AI_COMMANDER_FILE}
\`\`\`

---

## Performance Metrics

- **Analysis Duration:** ${execution_time}s
- **Files Processed:** ${TOTAL_FILES:-0}
- **Checks Performed:** ${TOTAL_CHECKS}
- **Self-Healing Actions:** ${AUTO_HEALS}

---

## Next Steps

### Immediate (0-24 hours)
- [ ] Review and address critical issues
- [ ] Test AI Commander fixes
- [ ] Run comprehensive test suite

### Short-term (1-7 days)
- [ ] Remove duplicate files
- [ ] Add missing documentation
- [ ] Improve test coverage

### Long-term (1-4 weeks)
- [ ] Achieve 5Ïƒ or better quality level
- [ ] Implement automated quality gates
- [ ] Set up continuous monitoring

---

**Report generated by Dig|lit Six Sigma Analysis Engine v${SCRIPT_VERSION}**  
*Striving for 99.99966% defect-free excellence*
REPORT_EOF

    # The eval syntax for variable expansion in the heredoc was fixed by using direct heredoc with variables expanded by bash automatically.

    success "Comprehensive report generated: ${REPORT_FILE}"

    generate_summary_file
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# QUICK SUMMARY GENERATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

generate_summary_file() {
    local summary_file="${Z_DIR}/PROJECT_STATUS.md"

    cat > "${summary_file}" << SUMMARY_EOF
# Dig|lit Project Status

**Last Updated:** $(date '+%Y-%m-%d %H:%M:%S')  
**Quality Level:** ${SIGMA_LEVEL}

## Quick Health Check

| Metric | Status | Value |
|--------|--------|-------|
| Sigma Level | $(if [[ ${DPMO:-999999} -le 3 ]]; then echo "ğŸŸ¢ Excellent"; elif [[ ${DPMO:-999999} -le 233 ]]; then echo "ğŸŸ¢ Good"; elif [[ ${DPMO:-999999} -le 6210 ]]; then echo "ğŸŸ¡ Fair"; else echo "ğŸ”´ Poor"; fi) | ${SIGMA_LEVEL} |
| Pass Rate | $(if awk "BEGIN {exit !(${PASS_RATE:-0} >= 95)}" 2>/dev/null; then echo "ğŸŸ¢"; elif awk "BEGIN {exit !(${PASS_RATE:-0} >= 80)}" 2>/dev/null; then echo "ğŸŸ¡"; else echo "ğŸ”´"; fi) | ${PASS_RATE}% |
| Critical Issues | $(if [[ ${CRITICAL_ISSUES} -eq 0 ]]; then echo "ğŸŸ¢ None"; else echo "ğŸ”´ ${CRITICAL_ISSUES}"; fi) | ${CRITICAL_ISSUES} |
| AI Commander | $(if [[ ${AI_BUGS_FOUND:-0} -eq 0 ]]; then echo "ğŸŸ¢ Healthy"; else echo "ğŸŸ¡ Issues"; fi) | ${AI_BUGS_FOUND:-0} bugs |
| Duplicates | $(if [[ ${DUP_COUNT:-0} -eq 0 ]]; then echo "ğŸŸ¢ Clean"; else echo "ğŸŸ¡ ${DUP_COUNT}"; fi) | ${DUP_COUNT:-0} files |
| Documentation | $(if awk "BEGIN {exit !(${DOC_RATIO:-0} >= 0.5)}" 2>/dev/null; then echo "ğŸŸ¢ Good"; elif awk "BEGIN {exit !(${DOC_RATIO:-0} >= 0.2)}" 2>/dev/null; then echo "ğŸŸ¡ Fair"; else echo "ğŸ”´ Poor"; fi) | ${DOC_RATIO} ratio |

## Component Status

### AI Commander
- **Status:** $([ ${AI_BUGS_FOUND:-0} -eq 0 ] && echo "âœ… Operational" || echo "âš ï¸ Needs Attention")
- **Bugs:** ${AI_BUGS_FOUND:-0} found
- **Fixes:** ${AI_FIXES_APPLIED:-0} applied
- **Quality:** ${AI_QUALITY_SCORE:-N/A}/100

### Project Structure
- **Total Files:** ${TOTAL_FILES:-0}
- **Code Files:** ${CODE_FILES:-0}
- **Docs:** ${DOC_FILES:-0}
- **Tests:** ${TEST_FILES:-0}

### Data Integrity
- **Duplicates:** ${DUP_COUNT:-0} exact matches
- **Similar Names:** ${SIMILAR_COUNT:-0} files
- **Backups Created:** $(ls -1 "${BACKUP_DIR}" 2>/dev/null | wc -l)

## Recent Activity

- **Last Analysis:** ${TIMESTAMP}
- **Execution Time:** $(($(date +%s) - START_TIME))s
- **Checks Run:** ${TOTAL_CHECKS}
- **Auto-Heals:** ${AUTO_HEALS}

## Quick Commands

\`\`\`bash
# Full analysis
./${SCRIPT_NAME} analyze

# Fix AI Commander
./${SCRIPT_NAME} fix-ai

# Check duplicates
./${SCRIPT_NAME} duplicates

# View full report
cat ${REPORT_FILE}

# View logs
tail -f ${LOG_FILE}
\`\`\`

## Latest Reports

- [Full Report](${REPORT_FILE})
- [Execution Log](${LOG_FILE})
- [Error Log](${ERROR_LOG})

---
*Auto-generated by Six Sigma Analysis Engine*
SUMMARY_EOF

    success "Quick status summary: ${summary_file}"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMMAND ROUTING & MAIN EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

execute_command() {
    local command="${1:-analyze}"

    case "${command}" in
        analyze|full)
            print_header "Six Sigma Full Analysis"
            validate_environment || critical "Environment validation failed"
            analyze_ai_commander
            analyze_project_structure
            detect_duplicates
            analyze_content_gaps
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        fix-ai)
            print_header "AI Commander Surgical Fix"
            validate_environment || critical "Environment validation failed"
            analyze_ai_commander
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        duplicates)
            print_header "Duplicate Detection Analysis"
            validate_environment || critical "Environment validation failed"
            detect_duplicates
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        structure)
            print_header "Project Structure Analysis"
            validate_environment || critical "Environment validation failed"
            analyze_project_structure
            analyze_content_gaps
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        validate)
            print_header "Environment & Configuration Validation"
            validate_environment
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        report)
            print_header "Generate Status Report"
            calculate_six_sigma_metrics
            generate_enhanced_report
            ;;

        help|--help|-h)
            show_help
            ;;

        version|--version|-v)
            echo "Dig|lit Six Sigma Analysis Engine ${SCRIPT_VERSION}"
            ;;

        *)
            error "Unknown command: ${command}"
            show_help
            exit 1
            ;;
    esac
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HELP DOCUMENTATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

show_help() {
    cat << 'HELP_EOF'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Dig|lit Six Sigma Analysis Engine                            â•‘
â•‘  Version 2.0.0                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USAGE:
    ./diglit.sh [COMMAND]

COMMANDS:
    analyze         Full Six Sigma analysis (default)
                    â€¢ AI Commander inspection
                    â€¢ Project structure analysis
                    â€¢ Duplicate detection
                    â€¢ Content gap analysis
                    â€¢ Quality metrics calculation

    fix-ai          Surgical AI Commander bug fixes
                    â€¢ Detect and fix syntax errors
                    â€¢ Validate Python compatibility
                    â€¢ Create automatic backups

    duplicates      Advanced duplicate file detection
                    â€¢ SHA256 checksum analysis
                    â€¢ Filename similarity detection
                    â€¢ Grouped duplicate reporting

    structure       Project structure analysis
                    â€¢ File type distribution
                    â€¢ Directory depth analysis
                    â€¢ Large file detection

    validate        Environment validation only
                    â€¢ Check required tools
                    â€¢ Verify permissions
                    â€¢ Validate configuration

    report          Generate status report
                    â€¢ Quality metrics
                    â€¢ Issue summary
                    â€¢ Recommendations

    help            Show this help message
    version         Show version information

EXAMPLES:
    # Run full analysis
    ./diglit.sh analyze

    # Fix AI Commander issues only
    ./diglit.sh fix-ai

    # Check for duplicate files
    ./diglit.sh duplicates

    # Validate environment setup
    ./diglit.sh validate

OUTPUT FILES:
    Z/REPORTS/report_*.md          Main analysis report
    Z/REPORTS/project_tree_*.txt   Complete file listing
    Z/REPORTS/duplicates_*.txt     Duplicate file report
    Z/LOGS/execution_*.log         Execution log
    Z/LOGS/errors_*.log            Error log
    Z/PROJECT_STATUS.md            Quick status summary

QUALITY LEVELS:
    6Ïƒ (Sigma)  = 3.4 DPMO      = World Class
    5Ïƒ (Sigma)  = 233 DPMO      = Excellent
    4Ïƒ (Sigma)  = 6,210 DPMO    = Good
    3Ïƒ (Sigma)  = 66,807 DPMO   = Average

For more information, visit: https://github.com/yourusername/diglit

HELP_EOF
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FINAL SUMMARY & CLEANUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

display_final_summary() {
    local end_time
    end_time=$(date +%s)
    local total_time=$((end_time - START_TIME))

    print_header "Analysis Complete - Six Sigma Results"

    echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${CYAN}â•‘         Six Sigma Quality Metrics            â•‘${NC}"
    echo -e "${CYAN}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${NC}"
    echo -e "${CYAN}â•‘${NC} Sigma Level:    ${BOLD}${SIGMA_LEVEL}${NC}"
    echo -e "${CYAN}â•‘${NC} DPMO:           ${DPMO}"
    echo -e "${CYAN}â•‘${NC} Pass Rate:      ${GREEN}${PASS_RATE}%${NC}"
    echo -e "${CYAN}â•‘${NC} Defect Rate:    ${YELLOW}${DEFECT_RATE}%${NC}"
    echo -e "${CYAN}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${NC}"
    echo -e "${CYAN}â•‘${NC} Total Checks:   ${TOTAL_CHECKS}"
    echo -e "${CYAN}â•‘${NC} Passed:         ${GREEN}${CHECKS_PASSED}${NC}"
    echo -e "${CYAN}â•‘${NC} Failed:         ${RED}${CHECKS_FAILED}${NC}"
    echo -e "${CYAN}â•‘${NC} Warnings:       ${YELLOW}${WARNINGS}${NC}"
    echo -e "${CYAN}â•‘${NC} Critical:       ${RED}${CRITICAL_ISSUES}${NC}"
    echo -e "${CYAN}â•‘${NC} Fixed:          ${GREEN}${ISSUES_FIXED}${NC}"
    echo -e "${CYAN}â•‘${NC} Auto-Healed:    ${GREEN}${AUTO_HEALS}${NC}"
    echo -e "${CYAN}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${NC}"
    echo -e "${CYAN}â•‘${NC} Execution Time: ${total_time}s"
    echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"

    echo ""

    echo -e "${CYAN}ğŸ“Š Detailed Reports:${NC}"
    echo -e "  ${BLUE}â€¢${NC} Main Report:   ${REPORT_FILE}"
    echo -e "  ${BLUE}â€¢${NC} Quick Status:  ${Z_DIR}/PROJECT_STATUS.md"
    echo -e "  ${BLUE}â€¢${NC} Execution Log: ${LOG_FILE}"
    echo -e "  ${BLUE}â€¢${NC} Error Log:     ${ERROR_LOG}"

    echo ""

    echo -e "${CYAN}ğŸ¯ Key Findings:${NC}"

    if [[ ${CRITICAL_ISSUES} -gt 0 ]]; then
        echo -e "  ${RED}âš ${NC}  ${CRITICAL_ISSUES} critical issues require immediate attention"
    fi

    if [[ ${AI_BUGS_FOUND:-0} -gt 0 ]]; then
        echo -e "  ${YELLOW}âš ${NC}  AI Commander: ${AI_BUGS_FOUND} bugs, ${AI_FIXES_APPLIED} fixed"
    else
        echo -e "  ${GREEN}âœ“${NC}  AI Commander passed all checks"
    fi

    if [[ ${DUP_COUNT:-0} -gt 0 ]]; then
        echo -e "  ${YELLOW}âš ${NC}  ${DUP_COUNT} duplicate files detected"
    else
        echo -e "  ${GREEN}âœ“${NC}  No duplicate files found"
    fi

    if [[ ${MISSING_CRITICAL:-0} -gt 0 ]]; then
        echo -e "  ${YELLOW}âš ${NC}  ${MISSING_CRITICAL} critical project files missing"
    else
        echo -e "  ${GREEN}âœ“${NC}  All critical files present"
    fi

    echo ""

    echo -e "${CYAN}ğŸš€ Quick Actions:${NC}"
    echo -e "  ${GREEN}1.${NC} Review report:    cat ${REPORT_FILE}"
    echo -e "  ${GREEN}2.${NC} Check status:     cat ${Z_DIR}/PROJECT_STATUS.md"
    echo -e "  ${GREEN}3.${NC} View duplicates:  cat ${DUPLICATES_FILE:-N/A}"
    echo -e "  ${GREEN}4.${NC} Start dev:        cd ${FRONTEND_DIR} && npm run dev"

    echo ""

    if [[ ${DPMO:-999999} -le 3 ]]; then
        echo -e "${GREEN}${BOLD}ğŸ† EXCELLENT! Project meets Six Sigma (6Ïƒ) standards!${NC}"
    elif [[ ${DPMO:-999999} -le 233 ]]; then
        echo -e "${GREEN}${BOLD}âœ… GREAT! Project achieves Five Sigma (5Ïƒ) quality!${NC}"
    elif [[ ${DPMO:-999999} -le 6210 ]]; then
        echo -e "${YELLOW}${BOLD}âš ï¸  GOOD. Project at Four Sigma (4Ïƒ) - room for improvement${NC}"
    else
        echo -e "${RED}${BOLD}âš ï¸  ATTENTION NEEDED. Quality below Four Sigma standards${NC}"
    fi

    echo ""
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCRIPT ENTRY POINT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

main() {
    init_logging

    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Dig|lit Six Sigma Analysis Engine ${SCRIPT_VERSION}"
    log_info "Started at: $(date '+%Y-%m-%d %H:%M:%S')"
    log_info "Working directory: ${PROJECT_ROOT}"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    execute_command "${1:-analyze}"

    display_final_summary

    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "Analysis completed at: $(date '+%Y-%m-%d %H:%M:%S')"
    log_info "Total execution time: $(($(date +%s) - START_TIME)) seconds"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    if [[ ${CRITICAL_ISSUES} -gt 0 ]]; then
        exit 2
    elif [[ ${CHECKS_FAILED} -gt 0 ]]; then
        exit 1
    else
        exit 0
    fi
}

main "$@"